[
  {
    "objectID": "posts/Visualization plotly/climate_database.html",
    "href": "posts/Visualization plotly/climate_database.html",
    "title": "Using Geographic, Boxplot, and Lineplot Visualizations to illustrate Global Warming",
    "section": "",
    "text": "import sqlite3\nimport pandas as pd\nimport numpy as np\nfrom matplotlib import pyplot as plt\nfrom sklearn.linear_model import LinearRegression\nfrom plotly import express as px\nimport plotly.io as pio\npio.renderers.default=\"iframe\"\n\n\n1. Database Creation\nFirst, create three separate tables: temperatures, countries, and stations table. To do so, I wrote a function named prepare_df to prepare the temperature dataset such that the data is easier to understand.\n\nThe temperatures table will contain station ID, year of measurement, month of measurement, and average temperature.\nThe countries table will contain country names and their corresponding country codes.\nThe stations table will contain station ID, latitude, longitude, elevation, and the name of the station.\n\n\ndef prepare_df(df):\n    df = df.set_index(keys=[\"ID\", \"Year\"])\n    df = df.stack()\n    df = df.reset_index()\n    df = df.rename(columns = {\"level_2\"  : \"Month\" , 0 : \"Temp\"})\n    df[\"Month\"] = df[\"Month\"].str[5:].astype(int)\n    df[\"Temp\"]  = df[\"Temp\"] / 100\n    df[\"NewID\"] = df[\"ID\"].str[0:2]\n    return(df)\n\n\nwith sqlite3.connect(\"HW1.db\") as conn: # create a database in current directory called temps.db\n    df_iter = pd.read_csv(\"temps.csv\", chunksize = 100000)\n    for i, df in enumerate(df_iter):\n        df = prepare_df(df)\n        df.to_sql(\"temperatures\", conn, if_exists = \"replace\" if i == 0 else \"append\", index = False)\n    url = \"station-metadata.csv\"\n    stations = pd.read_csv(url)\n    stations[\"NewID\"] = stations[\"ID\"].str[0:2]\n    stations.to_sql(\"stations\", conn, if_exists = \"replace\", index=False)\n    countries = pd.read_csv(\"countries.csv\")\n    countries = countries.rename(columns={\"FIPS 10-4\": \"NewID\"})\n    countries.to_sql(\"countries\", conn, if_exists = \"replace\", index=False)\n\nTemperatures dataframe\n\ndf.head() \n\n\n\n\n\n\n\n\nID\nYear\nMonth\nTemp\nNewID\n\n\n\n\n0\nUSW00014924\n2016\n1\n-13.69\nUS\n\n\n1\nUSW00014924\n2016\n2\n-8.40\nUS\n\n\n2\nUSW00014924\n2016\n3\n-0.20\nUS\n\n\n3\nUSW00014924\n2016\n4\n3.21\nUS\n\n\n4\nUSW00014924\n2016\n5\n13.85\nUS\n\n\n\n\n\n\n\nStations dataframe\n\nstations.head()\n\n\n\n\n\n\n\n\nID\nLATITUDE\nLONGITUDE\nSTNELEV\nNAME\nNewID\n\n\n\n\n0\nACW00011604\n57.7667\n11.8667\n18.0\nSAVE\nAC\n\n\n1\nAE000041196\n25.3330\n55.5170\n34.0\nSHARJAH_INTER_AIRP\nAE\n\n\n2\nAEM00041184\n25.6170\n55.9330\n31.0\nRAS_AL_KHAIMAH_INTE\nAE\n\n\n3\nAEM00041194\n25.2550\n55.3640\n10.4\nDUBAI_INTL\nAE\n\n\n4\nAEM00041216\n24.4300\n54.4700\n3.0\nABU_DHABI_BATEEN_AIR\nAE\n\n\n\n\n\n\n\nCountries dataframe\n\ncountries.head()\n\n\n\n\n\n\n\n\nNewID\nISO 3166\nName\n\n\n\n\n0\nAF\nAF\nAfghanistan\n\n\n1\nAX\n-\nAkrotiri\n\n\n2\nAL\nAL\nAlbania\n\n\n3\nAG\nDZ\nAlgeria\n\n\n4\nAQ\nAS\nAmerican Samoa\n\n\n\n\n\n\n\n\ndb_file = \"HW1.db\" #database we created \n\n\n\n2. Query Function\nBelow I created a query function query_climate_database which returns a dataframe based off of filters. The parameters specify the country, the year we start from, the year we end at, and the month we wish to analyze. The dataframe displays station name, latitude, longitude, and average temperature of the station during the month and year.\n\ndef query_climate_database(db_file, country, year_begin, year_end, month):\n    \"\"\"\n    Query function to filter climate data \n    \n    Args:\n    country: country of interest \n    year_begin: start year desired \n    year_end: end year desired \n    month: a specific month \n    \n    Return:\n    Dataframe of filtered data \n    \"\"\"\n    with sqlite3.connect(db_file) as conn:\n        cmd = \\\n        f\"\"\"\n        SELECT S.Name, S.LATITUDE, S.LONGITUDE, C.Name \"Country\", T.Year, T.Month, T.Temp\n        FROM stations S \n        LEFT JOIN countries C ON C.NewID = S.NewID\n        RIGHT JOIN temperatures T ON S.ID = T.ID \n        WHERE T.Year &lt;= {year_end} AND T.Year &gt;= {year_begin} AND T.Month = {month} AND C.Name = \"{country}\"\n        \"\"\" \n        df = pd.read_sql_query(cmd, conn)\n        return(df)\n\nBelow is an example with parameters country India, year_begin 1980, year_end 2020, and month 1\n\ndf = query_climate_database(db_file = \"HW1.db\", \n                            country = \"India\",\n                            year_begin = 1980, \n                            year_end = 2020, \n                            month = 1)\ndf\n\n\n\n\n\n\n\n\nNAME\nLATITUDE\nLONGITUDE\nCountry\nYear\nMonth\nTemp\n\n\n\n\n0\nPBO_ANANTAPUR\n14.583\n77.633\nIndia\n1980\n1\n23.48\n\n\n1\nPBO_ANANTAPUR\n14.583\n77.633\nIndia\n1981\n1\n24.57\n\n\n2\nPBO_ANANTAPUR\n14.583\n77.633\nIndia\n1982\n1\n24.19\n\n\n3\nPBO_ANANTAPUR\n14.583\n77.633\nIndia\n1983\n1\n23.51\n\n\n4\nPBO_ANANTAPUR\n14.583\n77.633\nIndia\n1984\n1\n24.81\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n3147\nDARJEELING\n27.050\n88.270\nIndia\n1983\n1\n5.10\n\n\n3148\nDARJEELING\n27.050\n88.270\nIndia\n1986\n1\n6.90\n\n\n3149\nDARJEELING\n27.050\n88.270\nIndia\n1994\n1\n8.10\n\n\n3150\nDARJEELING\n27.050\n88.270\nIndia\n1995\n1\n5.60\n\n\n3151\nDARJEELING\n27.050\n88.270\nIndia\n1997\n1\n5.70\n\n\n\n\n3152 rows Ã— 7 columns\n\n\n\n\n\n3. Geographic Mapbox Scatterplot\nWe use query_climate_database to create another function temperature_coefficient plot which answers how the average yearly change in temperature varies within a country. The function accepts the same parameters, as well as min_obs which will filters stations which do not have the specified number of data points. We also add **kwargs to customize our mapbox scatterplot we made using px.scatter_mapbox().\nInside our function, I wrote another function coef which conducts linear regression in order to compute how each station changes in average temperature over time.\n\ndef temperature_coefficient_plot(db_file, country, year_begin, year_end, month, min_obs, **kwargs):\n    \"\"\"\n    Construct a geographic mapbox scatterplot of yearly temperature increase\n    \n    Args:\n    country: desired country to display \n    year_begin: desired start year \n    year_end: desired end year \n    month: a specific month \n    min_obs: minimum required observations of station\n    **kwargs: additional keyword arguments\n    \n    Return:\n    Scatter_mapbox plot\n    \"\"\"\n    import calendar \n    def coef(data_group):\n        x = data_group[[\"Year\"]] # 2 brackets because X should be a df\n        y = data_group[\"Temp\"]   # 1 bracket because y should be a series\n        LR = LinearRegression()\n        LR.fit(x, y)\n        return LR.coef_[0]\n    df = query_climate_database(db_file, country, year_begin, year_end, month)\n    test = df.groupby([\"NAME\"]).size()\n    names = test[test &gt;= min_obs].index\n    df = df[df.NAME.isin(names)]\n    coefs = df.groupby([\"NAME\", \"Month\"]).apply(coef).round(4)\n    plot_df = pd.DataFrame(coefs)\n    merged_df = pd.merge(df, plot_df, on='NAME')\n    merged_df = merged_df.rename(columns={0: \"Estimated Yearly Increase (Celcius)\"})\n    fig = px.scatter_mapbox(merged_df, \n                            lat = \"LATITUDE\",\n                            lon = \"LONGITUDE\", \n                            hover_name=\"NAME\", \n                            color_continuous_midpoint = 0,\n                            color = \"Estimated Yearly Increase (Celcius)\",\n                            title = (f\"\"\"Estimates of yearly increase in {calendar.month_name[month]} \n                             &lt;br&gt;temperature for stations in {country}, from {year_begin} to {year_end}\"\"\"),\n                            **kwargs)\n    return(fig)\n\nBelow we create a sample plot with the same parameters we used in the query function along with new **kwargs parameters for the scatter_mapbox.\n\ncolor_map = px.colors.diverging.RdGy_r\nfig = temperature_coefficient_plot(db_file, \"India\", 1980, 2020, 1, 10,\n                                   zoom = 2,\n                                   mapbox_style=\"carto-positron\",\n                                   color_continuous_scale = color_map)\nfig.show()\n\n\n\n\nNow let us try this with a new example. Here I used the parameters country = Portugal, year_begin = 1980, year_end = 2020, and month = 2.\n\nfig = temperature_coefficient_plot(db_file, \"Portugal\", 1980, 2020, 2, \n                                   min_obs = 10,\n                                   zoom = 2,\n                                   mapbox_style=\"carto-positron\",\n                                   color_continuous_scale=color_map)\n\nfig.show()\n\n\n\n\n\n\n4. Additional Query Function and Plotly Boxplot and Lineplot\nI decided to write a query function which filters out only the equator countries. The reason why I did this was because I believe that it is valuable to see how the temperature changes each year from these equator countries because it may illustrate that even at the hottest parts of our world, the temperature increases, potentially infering global warming.\n\ndef query_equator(db_file, year_begin, year_end):\n    \"\"\"\n    Query function of only the Equator countries\n    \n    Args:\n    country: desired country to display \n    year_begin: desired start year \n    year_end: desired end year\n    \n    Return:\n    Dataframe with desired filters \n    \"\"\"\n    with sqlite3.connect(db_file) as conn:\n        cmd = \\\n        f\"\"\"\n        SELECT S.Name, S.LATITUDE, S.LONGITUDE, C.Name \"Country\", T.Year, T.Month, T.Temp\n        FROM stations S \n        LEFT JOIN countries C ON C.NewID = S.NewID\n        RIGHT JOIN temperatures T ON S.ID = T.ID \n        WHERE T.Year &lt;= {year_end} AND T.Year &gt;= {year_begin} AND S.LATITUDE &gt;= -5 AND S.LATITUDE &lt;= 5\n        AND (C.Name = \"Congo, Democratic Republic of the\" OR C.Name = \"Gabon\" \n        OR C.Name = \"Somalia\" \n        OR C.Name = \"Congo, Republic of the\" OR C.Name = \"Uganda\" \n        OR C.Name = \"Maldives\" OR C.Name = \"Indonesia\" OR C.Name = \"Kiribati\" \n        OR C.Name = \"Sao Tome and Principe\" OR C.Name = \"Kenya\" \n        OR C.Name = \"Ecuador\" OR C.Name = \"Colombia\" OR C.Name = \"Brazil\")\n        \"\"\" \n        df = pd.read_sql_query(cmd, conn)\n        return(df)\n\nHere I created a dataframe of just equator countries from 2010 - 2020.\n\ndf = query_equator(db_file, 2010, 2020)\ndf\n\n\n\n\n\n\n\n\nNAME\nLATITUDE\nLONGITUDE\nCountry\nYear\nMonth\nTemp\n\n\n\n\n0\nPORTO_DE_MOZ\n-1.733\n-52.233\nBrazil\n2010\n1\n27.69\n\n\n1\nPORTO_DE_MOZ\n-1.733\n-52.233\nBrazil\n2010\n2\n28.11\n\n\n2\nPORTO_DE_MOZ\n-1.733\n-52.233\nBrazil\n2010\n3\n28.85\n\n\n3\nPORTO_DE_MOZ\n-1.733\n-52.233\nBrazil\n2010\n4\n27.79\n\n\n4\nPORTO_DE_MOZ\n-1.733\n-52.233\nBrazil\n2010\n5\n28.27\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n16227\nMASINDI\n1.683\n31.717\nUganda\n2011\n8\n21.98\n\n\n16228\nMASINDI\n1.683\n31.717\nUganda\n2011\n9\n22.09\n\n\n16229\nMASINDI\n1.683\n31.717\nUganda\n2011\n10\n23.01\n\n\n16230\nMASINDI\n1.683\n31.717\nUganda\n2011\n11\n23.29\n\n\n16231\nMASINDI\n1.683\n31.717\nUganda\n2011\n12\n24.50\n\n\n\n\n16232 rows Ã— 7 columns\n\n\n\nThe temperature_box_plot function below addresses how the average temperature of countries on the equator change year to year. I made sure that the function uses the same station for every year such that the data is not unevenly weighted. The plot which this function produces is important because we can see if our temperature is rising or lowering as time goes on. And as we can see from the figure below, there is a slight gradual increase in the boxplot medians of Brazil, providing visual evidence that temperatures are increasing for equator countries.\n\ndef temperature_box_plot(db_file, country, year_begin, year_end, **kwargs):\n    \"\"\"\n    Construct boxplot of yearly average temperatures of specified equator country \n    \n    Args:\n    country: desired country to display \n    year_begin: desired start year \n    year_end: desired end year \n    \n    Return:\n    px.box plot of yearly average temperatures of specified equator country\n    \"\"\"\n    df = query_equator(db_file, year_begin, year_end)\n    df = df[df.Country == country]\n    new = df.groupby([\"NAME\", \"Year\"])[\"Temp\"].aggregate(np.mean)\n    test = df.groupby([\"NAME\", \"Year\"]).size()\n    test = test.reset_index()\n    names = test.groupby([\"NAME\"]).size() &gt;= year_end - year_begin + 1 \n    names = names[names].index\n    plot_df = pd.DataFrame(new)\n    plot_df = plot_df.reset_index()\n    plot_df = plot_df[plot_df.NAME.isin(names)]\n    fig = px.box(df,\n                 x = \"Country\",\n                 y = \"Temp\",\n                 color = \"Year\",\n                 title = f\"Boxplots of {country}'s Average Temperature by Year from {year_begin} to {year_end}\",\n                 category_orders={\"Year\": [ix for ix in range(year_begin, year_end)]},\n                 **kwargs\n                )\n    return fig\n\n\nfig = temperature_box_plot(db_file, \"Brazil\", 1980, 2020)\nfig.show()\n\n\n\n\nI constructed the temperature_lineplot_equator function to display a lineplot of how the temperature changes over time in each month, and each colored line on the lineplot represents a different station. I felt this was important because like the boxplot it was another way to visualize how there is an increase in temperature in equator countries. For instance, as we can see below the Average Temperature of Station in Indonesia from 1985 to 2020 increased for all 4 stations plotted.\n\ndef temperature_lineplot_equator(db_file, year_begin, year_end, country, month, **kwargs):\n    \"\"\"\n    Construct lineplot of yearly average temperatures of specified equator country in month\n    \n    Args:\n    country: desired country to display \n    year_begin: desired start year \n    year_end: desired end year \n    month: specific month of year\n    **kwargs: keyword arguments for lineplot\n    \n    Return:\n    px.line plot of yearly average temperatures of specified equator country\n    \"\"\"\n    import calendar \n    df = query_equator(db_file, year_begin, year_end)\n    df = df[df.Month == month]\n    df[\"Date\"] = pd.to_datetime(df[\"Year\"].astype(str) + \"-\" + df[\"Month\"].astype(str))\n    df = df[df.Country == country]\n    new = df.groupby([\"NAME\", \"Date\"])[\"Temp\"].aggregate(np.mean)\n    test = df.groupby([\"NAME\", \"Date\"]).size()\n    test = test.reset_index()\n    names = test.groupby([\"NAME\"]).size() &gt;= (year_end - year_begin) - 5  \n    names = names[names].index\n    plot_df = pd.DataFrame(new)\n    plot_df = plot_df.reset_index()\n    plot_df = plot_df[plot_df.NAME.isin(names)]\n    fig = px.line(data_frame = plot_df,\n                  x = \"Date\",\n                  y = \"Temp\",\n                  color = \"NAME\",\n                  title = (f\"\"\"Average Temperature of Station in {country} &lt;br&gt;\n                           by Year in {calendar.month_name[month]} from {year_begin} to {year_end}\"\"\"),\n                  )\n    return(fig)\n\n\nplot = temperature_lineplot_equator(db_file, 1985, 2020, \"Indonesia\", 6)\nplot.show()\n\n\n\n\n\n\n5. Concluding Remarks\nAs we can see from the query functions and graphics constructed, there is overwhelming evidence for global warming. The mapbox plot, boxplot, and line plots all show that there is a majority increase in temperature, and this conclusion was able to be realized because the visualizations helped to easily explain the data."
  },
  {
    "objectID": "posts/bruins/HW0- Blog Tutorial.html",
    "href": "posts/bruins/HW0- Blog Tutorial.html",
    "title": "Blog Tutorial HW0",
    "section": "",
    "text": "First read in the data\n\nimport pandas as pd\nurl = \"https://raw.githubusercontent.com/pic16b-ucla/24W/main/datasets/palmer_penguins.csv\"\npenguins = pd.read_csv(url)\n\n\n\nNow letâ€™s look at the first few rows of the dataset.\n\npenguins.head()\n\nIt appears that there are a few numeric columns in our dataframe which would be easy to analyze. Letâ€™s specifically look at two and plot them on a scatter plot.\n\n\nLetâ€™s import the seaborn package and create a scatterplot\nFor this example, I chose â€˜Culmen Lengthâ€™ and â€™Flipper Length). I imported the seaborn package as it has great functions for visualization. I chose to create a scatterplot because it is the best way to analyze numeric data against numeric data.\n\nimport seaborn as sns\n\nsns.scatterplot(\n    data = penguins,\n    x = \"Culmen Length (mm)\", \n    y = \"Flipper Length (mm)\")\n\n\n\n\n\n\n\n\nIt appears that there is a positive relationship between culmen length and flipper length.\n\n\nNow go one step further!\nLetâ€™s go even further through analyzing if the type of species affects this relationship. To do this, we add the hue parameter. I also used the set_title function to make our plot look even better!\n\nsns.scatterplot(\n    data = penguins,\n    x = \"Culmen Length (mm)\", \n    y = \"Flipper Length (mm)\", \n    hue = \"Species\").set_title(\"Flipper Length vs Culmen Length in mm vs Species\")\n\nText(0.5, 1.0, 'Flipper Length vs Culmen Length in mm vs Species')\n\n\n\n\n\n\n\n\n\nAs we can see, species type does seem to affect the culmen length and flipper length values. For instance, there appears to be distinct groupings based upon species type, as the Gentoo Penguin appears to have the longest dimensions with the adelie penguins and chinstrap penguins having similar flipper lengths but differing culmen lengths.\n\n\nWeâ€™re done!"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Blog",
    "section": "",
    "text": "Webscraping â€˜The Boysâ€™ with Scrapy\n\n\n\n\n\n\nWebscraping\n\n\nScrapy\n\n\n\n\n\n\n\n\n\nFeb 5, 2024\n\n\nTyler Nguyen\n\n\n\n\n\n\n\n\n\n\n\n\nUsing Geographic, Boxplot, and Lineplot Visualizations to illustrate Global Warming\n\n\n\n\n\n\nSQLITE\n\n\nVisualization\n\n\n\n\n\n\n\n\n\nJan 23, 2024\n\n\nTyler Nguyen\n\n\n\n\n\n\n\n\n\n\n\n\nBlog Tutorial HW0\n\n\n\n\n\n\nweek 0\n\n\nhomework\n\n\n\n\n\n\n\n\n\nJan 22, 2024\n\n\nTyler Nguyen\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/TMDB_scraper/TMDB.html",
    "href": "posts/TMDB_scraper/TMDB.html",
    "title": "Webscraping â€˜The Boysâ€™ with Scrapy",
    "section": "",
    "text": "What movie or TV shows share actors with your favorite movie or show?\nWe will use webscraping to solve the above question in this blog post.\nThis post has two parts. In the first, we go over webscraping for finding shared actors on TMDB. In the second, we use the webscraperâ€™s results to make a visualization."
  },
  {
    "objectID": "posts/TMDB_scraper/TMDB.html#a.-pick-a-movie-or-tv-show",
    "href": "posts/TMDB_scraper/TMDB.html#a.-pick-a-movie-or-tv-show",
    "title": "Webscraping â€˜The Boysâ€™ with Scrapy",
    "section": "a. Pick a Movie or TV Show",
    "text": "a. Pick a Movie or TV Show\nFirst, we pick a tv show. I used my favorite show The Boys. The link to its TMDB page is here: https://www.themoviedb.org/tv/76479-the-boys"
  },
  {
    "objectID": "posts/TMDB_scraper/TMDB.html#b.-project-initialization",
    "href": "posts/TMDB_scraper/TMDB.html#b.-project-initialization",
    "title": "Webscraping â€˜The Boysâ€™ with Scrapy",
    "section": "b. Project Initialization",
    "text": "b. Project Initialization\nWe will now create a GitHub repository which will contain our Scrapy files. After, we open a terminal in the location we wish our files to be and type:\nscrapy startproject TMDB_scraper\nscd TMDB_scraper"
  },
  {
    "objectID": "posts/TMDB_scraper/TMDB.html#c.-alter-settings",
    "href": "posts/TMDB_scraper/TMDB.html#c.-alter-settings",
    "title": "Webscraping â€˜The Boysâ€™ with Scrapy",
    "section": "c.Â Alter Settings",
    "text": "c.Â Alter Settings\nNow lets alter the settings.py file. We need to modify the User_Agent variable to equal Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/109.0.0.0 Safari/537.36 such that we will not get 403 errors while scraping.\nWe also add the line CLOSESPIDER_PAGECOUNT = 20 to prevent our webscraper from scraping too many pages."
  },
  {
    "objectID": "posts/TMDB_scraper/TMDB.html#a.-parseself-response",
    "href": "posts/TMDB_scraper/TMDB.html#a.-parseself-response",
    "title": "Webscraping â€˜The Boysâ€™ with Scrapy",
    "section": "a. parse(self, response)",
    "text": "a. parse(self, response)\n\ndef parse(self, response):\n        \"\"\"\n        Sends webscraper to the full cast and crew page \n        \"\"\"\n        next_page = response.css(\"a[href*=cast]::attr(href)\").get() #css command to redirect to the full cast page url\n        yield response.follow(next_page, callback = self.parse_full_credits) #redirects to the new url page and executes parse_full_credits\n\nThe response variable inside parse is the page we are inspecting. The variable next_page corresponds to the next page we wish to scrape. The value inside response.css was the css command used to redirect to the full cast url page. Finally we used yield response.follow in order to go to this next url, and the callback parameter we wrote is the function which we next execute."
  },
  {
    "objectID": "posts/TMDB_scraper/TMDB.html#b.-parse_full_creditsself-response",
    "href": "posts/TMDB_scraper/TMDB.html#b.-parse_full_creditsself-response",
    "title": "Webscraping â€˜The Boysâ€™ with Scrapy",
    "section": "b. parse_full_credits(self, response)",
    "text": "b. parse_full_credits(self, response)\n\ndef parse_full_credits(self, response):\n        \"\"\"\n        Sends webscraper to the individual actor's page\n        \"\"\"\n        actor_list = response.css('ol.people.credits:not(.crew) div.info  a[href*= \"person/\"]::attr(href)').getall()[0:20]\n        for actor in actor_list: #for every actor in the actor list url, execute the callback command parse_actor_page \n            yield response.follow(actor, callback = self.parse_actor_page)\n\nThe function which parse yields does the same thing parse does except it inspects the new response variable passed which is the full cast page. The variable actor_list corresponds to the next page we wish to next scrape and I choose to include only the first 20 actors in this list. The css command we used was to redirect to each individual actorâ€™s page. Finally, we also used response.follow again in order to go to the individual actorâ€™s url page, and the callback function wish we need to execute next is self.parse_actor_page."
  },
  {
    "objectID": "posts/TMDB_scraper/TMDB.html#c.-parse_actor_pageself-response",
    "href": "posts/TMDB_scraper/TMDB.html#c.-parse_actor_pageself-response",
    "title": "Webscraping â€˜The Boysâ€™ with Scrapy",
    "section": "c.Â parse_actor_page(self, response)",
    "text": "c.Â parse_actor_page(self, response)\n\ndef parse_actor_page(self, response):\n        \"\"\"\n        Returns a dictionary of every actor and each movie they worked on\n        \"\"\"\n        actor = response.css(\"h2.title a::text\").get() #css command which displays actor name \n        movies = response.css(\"a.tooltip bdi::text\").getall() #css command which displays each movie/TV show actor worked on\n        for work in movies: #for every movie/TV show in movie/TV show list \n            yield { #create a dictionary with actor name and movie/TV show \n                \"actor\": actor,\n                \"movie_or_TV_name\" : work\n            }\n\nThis function does the same thing the above two functions except it inspects the new response variable passed which is the individual actors page. We extract the actor names and every movie/TV show this actor worked on and store them in the actor and movies variables. Finally, we create a for loop to go over each work per actor, and uses these variables to create a dictionary of {\"actor\": actor, \"movie_or_TV_name\": work}."
  },
  {
    "objectID": "posts/TMDB_scraper/TMDB.html#insights-and-recommendations",
    "href": "posts/TMDB_scraper/TMDB.html#insights-and-recommendations",
    "title": "Webscraping â€˜The Boysâ€™ with Scrapy",
    "section": "3. Insights and Recommendations",
    "text": "3. Insights and Recommendations\nWe now run the following command in our terminal to create a csv file named results2.csv containing our data:\nscrapy crawl tmdb_spider -o results2.csv -a subdir=76479-the-boys\nLet us now anaylze the results.\n\nimport pandas as pd \ndf = pd.read_csv(\"results2.csv\")\ndf\n\n\n\n\n\n\n\n\nactor\nmovie_or_TV_name\n\n\n\n\n0\nKarl Urban\nARK: The Animated Series\n\n\n1\nKarl Urban\nMortal Kombat 2\n\n\n2\nKarl Urban\nI, Object\n\n\n3\nKarl Urban\nGen V\n\n\n4\nKarl Urban\nThe Sea Beast\n\n\n...\n...\n...\n\n\n813\nJessie T. Usher\nLevel Up\n\n\n814\nJessie T. Usher\nThe Mentalist\n\n\n815\nJessie T. Usher\nHannah Montana\n\n\n816\nJessie T. Usher\nCriminal Minds\n\n\n817\nJessie T. Usher\nWithout a Trace\n\n\n\n\n818 rows Ã— 2 columns\n\n\n\n\npopular = df.groupby(\"movie_or_TV_name\").count().sort_values(ascending = False, by = \"actor\")[0:24]\npopular.columns = [\"Actor Count\"]\npopular\n\n\n\n\n\n\n\n\nActor Count\n\n\nmovie_or_TV_name\n\n\n\n\n\nThe Boys\n21\n\n\nPrime Rewind: Inside The Boys\n10\n\n\nGen V\n8\n\n\nThe Boys Presents: Diabolical\n6\n\n\nLaw & Order\n4\n\n\nLaw & Order: Special Victims Unit\n4\n\n\nMano\n3\n\n\nThe Kelly Clarkson Show\n3\n\n\nThe Show\n3\n\n\nDeception\n3\n\n\nLate Night with Seth Meyers\n3\n\n\nTimeless\n3\n\n\nThe Equalizer\n3\n\n\nGen V - Prime Premiere\n3\n\n\nUndrafted\n2\n\n\nPerson of Interest\n2\n\n\nThe Ellen DeGeneres Show\n2\n\n\nParish\n2\n\n\nBones\n2\n\n\nDylan & Zoey\n2\n\n\nAunty Donna's Big Ol House of Fun\n2\n\n\nLevel Up\n2\n\n\nHalf & Half\n2\n\n\nSoul Food\n2\n\n\n\n\n\n\n\nAs we can see from the subset of the data above, some movies and TV shows are more popular than others. Obviously The Boys will be the most popular one because it is where we got our actor list from. So we create a pie graph which will show the next popular movies/TV shows.\n\nfrom plotly import express as px \nimport plotly.io as pio\npio.renderers.default=\"iframe\"\n\n\nfig = px.pie(popular, values='Actor Count', names=popular.index, title='Top Recommendations')\nfig.update_traces(textposition='inside', textinfo='label+text')\nfig.show()\n\n\n\n\nAs we can see the pie graph clearly gives us the most popular movies. Obviously The Boys is first and we can see that the next three most popular are spin offs of the TV Show, Prime Rewind: Inside the Boys, Gen V, and The Boys Presents: Diabolical. The popular ones not related to the boys are Law & Order, Law  Order: Special Victims Unit, and Mano*.\nNice, now we are done!"
  }
]